{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "import uuid  # Import UUID module\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.mangadex.org/manga?limit=32&offset=32\n",
    "# https://api.mangadex.org/manga?limit=32&offset=32+32\n",
    "# https://api.mangadex.org/statistics/manga?manga[]=6f1f3a84-f2e3-4512-93bf-009fd12cfce6\n",
    "# https://api.mangadex.org/manga/a15dc49f-2512-46f2-bc1e-201be8234ee5?includes[]=artist&includes[]=author&includes[]=cover_art\n",
    "# https://mangadex.org/covers/a15dc49f-2512-46f2-bc1e-201be8234ee5/c20365e1-285a-4e93-b701-9fd03ff4ae19.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit = 32\n",
    "# offset = limit\n",
    "# url = 'https://api.mangadex.org/manga?limit=' + str(limit) + '&offset=' + str(offset)\n",
    "# response = requests.get(url)\n",
    "# data = response.json()\n",
    "# page_count = (round(data['total'] / 248))\n",
    "\n",
    "# for i in range(1, page_count):\n",
    "#     offset += limit\n",
    "#     url = 'https://api.mangadex.org/manga?limit=' + str(limit) + '&offset=' + str(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 32\n",
    "offset = limit\n",
    "url = 'https://api.mangadex.org/manga?limit=' + str(limit) + '&offset=' + str(offset)\n",
    "url_stat = 'https://api.mangadex.org/statistics/manga?manga[]='\n",
    "\n",
    "def download_image(img_url, save_path):\n",
    "    if not img_url.startswith(('http://', 'https://')):\n",
    "        print(f\"Invalid URL for {save_path}. Saving a gray placeholder image instead.\")\n",
    "        # Create a 225x225 gray image using PIL as a placeholder\n",
    "        img = Image.new('RGB', (225, 225), color='gray')\n",
    "        img.save(save_path)\n",
    "    else:\n",
    "        try:\n",
    "            # Get the image from the valid URL\n",
    "            get_image = requests.get(img_url)\n",
    "            with open(save_path, 'wb') as file:\n",
    "                file.write(get_image.content)\n",
    "                \n",
    "            print(f\"Image downloaded for {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download image for {save_path}: {e}\")\n",
    "            # Save a gray image in case of failure\n",
    "            img = Image.new('RGB', (225, 225), color='gray')\n",
    "            img.save(save_path)\n",
    "            \n",
    "def getdataurl(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        json = []\n",
    "        lan = ['en', 'ja', 'ko', 'ru', 'zh', 'ko-ro', 'zh-hk','es-la']\n",
    "        data = response.json()\n",
    "        \n",
    "        for comic in data['data']:\n",
    "            url_manga = 'https://api.mangadex.org/manga'\n",
    "            url_cover = 'https://mangadex.org/covers'\n",
    "            id = comic['id']\n",
    "            \n",
    "            title = next((v for k, v in comic['attributes']['title'].items() if k in lan), None)\n",
    "            description = next((v for k, v in comic['attributes']['description'].items() if k in lan), None)\n",
    "            \n",
    "            alt_titles = []\n",
    "            for alt_title_dict in comic['attributes'].get('altTitles', []):\n",
    "                alt_title = next((v for k, v in alt_title_dict.items() if k in lan), None)\n",
    "                if alt_title:\n",
    "                    alt_titles.append(alt_title)\n",
    "            alt_titles = ', '.join(alt_titles)\n",
    "            \n",
    "            genres = []\n",
    "            for tag in comic['attributes'].get('tags', []):\n",
    "                tag_name = next((v for k, v in tag['attributes']['name'].items() if k in ['en', 'ja', 'ko']), None)\n",
    "                if tag_name:\n",
    "                    genres.append(tag_name)\n",
    "            genres = ', '.join(genres)\n",
    "        \n",
    "            released = comic['attributes']['year'] if comic['attributes']['year'] and int(comic['attributes']['year']) else '-'\n",
    "            \n",
    "            rate = 0\n",
    "            response_rate = requests.get(url_stat+id)\n",
    "            if response_rate.status_code == 200:\n",
    "                data_stat = response_rate.json()\n",
    "                rate = data_stat['statistics'][id]['rating']['average']\n",
    "\n",
    "            author = ''\n",
    "            artist = ''\n",
    "            img = ''\n",
    "            url_manga += '/'+id+'?includes[]=artist&includes[]=author&includes[]=cover_art'\n",
    "            response_manga = requests.get(url_manga)\n",
    "            if response_manga.status_code == 200:\n",
    "                data_manga = response_manga.json()\n",
    "                for relation in data_manga['data']['relationships']:\n",
    "                    if relation['type'] == 'author' and 'attributes' in relation and 'name' in relation['attributes']:\n",
    "                        author = relation['attributes']['name']\n",
    "                    if relation['type'] == 'artist' and 'attributes' in relation and 'name' in relation['attributes']:\n",
    "                        artist = relation['attributes']['name']\n",
    "                    if relation['type'] == 'cover_art' and 'attributes' in relation and 'fileName' in relation['attributes']:\n",
    "                        img = f\"{url_cover}/{id}/{relation['attributes']['fileName']}\"\n",
    "\n",
    "            uuid_data = str(uuid.uuid4())\n",
    "            \n",
    "            json.append({\n",
    "                'id': uuid_data,\n",
    "                'title': title,\n",
    "                'alt_title': alt_titles,\n",
    "                'type': comic['type'],\n",
    "                'description': description,\n",
    "                'genre': genres,\n",
    "                'author':author,\n",
    "                'artist':artist,\n",
    "                'rate': rate,\n",
    "                'image': img,\n",
    "                'released': released,\n",
    "            })\n",
    "            \n",
    "            if not os.path.exists('image'):\n",
    "                os.makedirs('image')\n",
    "                \n",
    "            download_image(img, f'image/{uuid_data}.jpg')\n",
    "            \n",
    "        return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "limit = 32\n",
    "offset = limit\n",
    "url = 'https://api.mangadex.org/manga?limit=' + str(limit) + '&offset=' + str(offset)\n",
    "data = (requests.get(url)).json()\n",
    "page_count = (round(data['total'] / 248))\n",
    "\n",
    "# get data manually 300 page's\n",
    "indexNum = 0 # 901 # 701 # 601 # 501 # 401 #315 # 201 # 100 # 0\n",
    "page_count = 1100 # 1100 # 901 # 701 # 601 # 501 # 401 # 315 # 201 # 100\n",
    "\n",
    "for start in range(indexNum, page_count, 100):\n",
    "    end = min(start + 100, page_count)\n",
    "    json_data = []\n",
    "    \n",
    "    for i in range(indexNum, page_count):\n",
    "        offset += limit\n",
    "        url = 'https://api.mangadex.org/manga?limit=' + str(limit) + '&offset=' + str(offset)\n",
    "        getdata = getdataurl(url)\n",
    "        df = df + getdata\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        \n",
    "    df.to_csv(f'data/mangadex-{end}.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/mangadex.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
